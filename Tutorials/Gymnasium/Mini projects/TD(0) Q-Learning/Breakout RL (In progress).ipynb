{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:14:33.100913400Z",
     "start_time": "2024-07-19T18:14:33.075908300Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict # allows access to undefined keys\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg' if you prefer Qt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LunarLanderAgent:\n",
    "    def __init__(self,\n",
    "                 learning_rate: float,\n",
    "                 initial_epsilon: float,\n",
    "                 epsilon_decay: float,\n",
    "                 final_epsilon: float,\n",
    "                 discount_factor: float = 0.95,\n",
    "                 discrete_actions: int = 4):\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "        self.discrete_actions = discrete_actions\n",
    "        \n",
    "        # Initialize Q-table\n",
    "        self.q_values = defaultdict(lambda: np.zeros(self.discrete_actions))\n",
    "        \n",
    "        self.training_error = []\n",
    "    \n",
    "    def discretize_state(self, state):\n",
    "        # Round each value in the state to 1 decimal place\n",
    "        # Convert to tuple for hashability\n",
    "        # print(state)\n",
    "        # Append the original terminated flag (boolean)\n",
    "        return tuple(np.append(state, state[-1])) \n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        discretized_state = self.discretize_state(state)\n",
    "        \n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.randint(self.discrete_actions)\n",
    "        else:\n",
    "            return int(np.argmax(self.q_values[discretized_state]))\n",
    "    \n",
    "    def update_q_values(self, state, action, reward, terminated, next_state):\n",
    "        state = self.discretize_state(state)\n",
    "        # print('state shape : ', state[0].shape)\n",
    "        next_state = self.discretize_state(next_state)\n",
    "        \n",
    "        if not terminated:          \n",
    "            future_q_value = np.max(self.q_values[next_state])\n",
    "        else:\n",
    "            future_q_value = 0\n",
    "        temporal_difference = (reward + (self.discount_factor * future_q_value)) - self.q_values[state][action]\n",
    "        self.q_values[state][action] += self.lr * temporal_difference\n",
    "        self.training_error.append(temporal_difference)\n",
    "        \n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.final_epsilon, self.epsilon * self.epsilon_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:14:33.122918900Z",
     "start_time": "2024-07-19T18:14:33.106915200Z"
    }
   },
   "id": "71382b775326e544",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "n_episodes = 100\n",
    "start_epsilon = 1\n",
    "epsilon_decay = 0.99\n",
    "final_epsilon = 0.05\n",
    "\n",
    "agent = LunarLanderAgent(\n",
    "    learning_rate=learning_rate,\n",
    "    initial_epsilon=start_epsilon,\n",
    "    final_epsilon=final_epsilon,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    \n",
    "    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:14:33.153925800Z",
     "start_time": "2024-07-19T18:14:33.138922Z"
    }
   },
   "id": "ef93af5919d22a69",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/Breakout-v5\", render_mode='rgb_array')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:14:33.264951100Z",
     "start_time": "2024-07-19T18:14:33.169929100Z"
    }
   },
   "id": "40360a309c0449ea",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space shape : 4\n",
      "observation space shape : Box(0, 255, (210, 160, 3), uint8)\n",
      "reward range : (-inf, inf)\n",
      "\n",
      "Env metadata : {'render_modes': ['human', 'rgb_array'], 'obs_types': {'grayscale', 'ram', 'rgb'}}\n"
     ]
    }
   ],
   "source": [
    "print(f'action space shape : {env.action_space.n}') # Number of possible actions is 4\n",
    "print(f'observation space shape : {env.observation_space}') \n",
    "#-------------- obesrvation is a tupe of 3 values : --------------\n",
    "#1) player cards value\n",
    "#2) dealer's face up card\n",
    "#3) usable ace for player, equal 1 if ace is considered an 11 without busting\n",
    "\n",
    "print(f'reward range : {env.reward_range}') # default reward range is set to -inf +inf\n",
    "# print(f'\\nEnv specs : {env.spec}') \n",
    "print(f'\\nEnv metadata : {env.metadata}') # render_modes adn render_fps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:14:33.311961400Z",
     "start_time": "2024-07-19T18:14:33.281955Z"
    }
   },
   "id": "3eb665b43b59db0e",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:43<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "env = gym.wrappers.RecordEpisodeStatistics(env, deque_size=n_episodes)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=60)\n",
    "\n",
    "rewards = 0 \n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    # play one episode\n",
    "    while not done:\n",
    "        action = agent.choose_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards += reward\n",
    "        # update the agent\n",
    "        agent.update_q_values(obs, action, reward, terminated, next_obs)\n",
    "\n",
    "        # update if the environment is done and the current obs\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "\n",
    "    agent.decay_epsilon()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:16:16.549018100Z",
     "start_time": "2024-07-19T18:14:33.314961800Z"
    }
   },
   "id": "f66e0e3d2ae896c4",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "q_values = np.array([value for key, value in agent.q_values.items()])\n",
    "print(np.argmax(q_values,axis=1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:16:16.664250700Z",
     "start_time": "2024-07-19T18:16:16.585463900Z"
    }
   },
   "id": "fa5d6e44bd8378ae",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rewards = 18.0\n"
     ]
    }
   ],
   "source": [
    "print(f'total rewards = {rewards}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:16:16.701339500Z",
     "start_time": "2024-07-19T18:16:16.681335400Z"
    }
   },
   "id": "7c08f6b5a0cde63e",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:  obs = [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]] , reward = 0.0\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "can't invoke \"update\" command: application has been destroyed",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTclError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 30\u001B[0m\n\u001B[0;32m     27\u001B[0m action_text\u001B[38;5;241m.\u001B[39mset_text(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStep: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mactions[action]\u001B[38;5;250m \u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     29\u001B[0m fig\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mdraw()\n\u001B[1;32m---> 30\u001B[0m \u001B[43mfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush_events\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m done \u001B[38;5;241m=\u001B[39m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated\n\u001B[0;32m     32\u001B[0m obs \u001B[38;5;241m=\u001B[39m next_obs\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\.venv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:414\u001B[0m, in \u001B[0;36mFigureCanvasTk.flush_events\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflush_events\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;66;03m# docstring inherited\u001B[39;00m\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tkcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tkinter\\__init__.py:1314\u001B[0m, in \u001B[0;36mMisc.update\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1313\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1314\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mupdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTclError\u001B[0m: can't invoke \"update\" command: application has been destroyed"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"ALE/Breakout-v5\",render_mode='rgb_array')\n",
    "# env = CustomRewardWrapper(env)\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "action_text = ax.text(510, 20, '', color='white', fontsize=12, bbox=dict(facecolor='blue', alpha=0.8))\n",
    "img = ax.imshow(env.render())\n",
    "actions = ['Move Up','Move Right','Move Down','Move Left']\n",
    "rewards = 0\n",
    "num_epochs= 10\n",
    "for step in range(num_epochs):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    print(f'step {step}:  obs = {next_obs} , reward = {reward}')\n",
    "    while not done:\n",
    "        action = agent.choose_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards += reward\n",
    "        if reward >10 : \n",
    "            print(f'step {step}:  obs = {next_obs} , reward = {reward}')\n",
    "\n",
    "        frame = env.render()\n",
    "        img.set_data(frame)\n",
    "        action_text.set_text(f'Step: {actions[action] }')\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "plt.show()  # Keep the window open after the animation finishes\n",
    "plt.close()\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:34:47.735433400Z",
     "start_time": "2024-07-19T18:34:37.262922500Z"
    }
   },
   "id": "795a6112a7a42623",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean episode rewards = 1.2\n"
     ]
    }
   ],
   "source": [
    "print(f'mean episode rewards = {rewards/num_epochs}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-19T18:34:28.915822800Z",
     "start_time": "2024-07-19T18:34:28.890817100Z"
    }
   },
   "id": "26a84eafbb54162e",
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
