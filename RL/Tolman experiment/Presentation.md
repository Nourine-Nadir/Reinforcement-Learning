This idea of implementing the Tolman experiment he runned on rats to analyze their behavior on reaching a goal depending on the rewards they get struck
me quickly while listening to a podcast about neurology.

Working on reinforcement learning and getting the 'AI' tag is pretending that your agent match more or less the behavior of a human, giving that rats brains
match at a high percentage human ones this is one of the methods i think we should apply to prove the efficiency of our algorithms used
in Reinforcement Learning.

1st notice I had is that the reason of this rapid learning is the big training error occurring after getting null reward for long time so the difference
between these first rewards and the new ones is big so the gradient converge faster.

2nd reason 